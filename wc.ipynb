{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d557741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httplib2\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import os\n",
    "import platform\n",
    "import time\n",
    "import json\n",
    "from PyPDF2 import PdfFileReader\n",
    "from openpyxl import load_workbook\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import array\n",
    "from time import sleep\n",
    "from os.path import exists\n",
    "from google_play_scraper import app\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "508b7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click privacy policy button, pass in webdriver and data safety urls with privacy policy button on page\n",
    "def press_button(driver, data_url):\n",
    "    driver.implicitly_wait(1)\n",
    "    driver.get(data_url)\n",
    "    print(data_url)\n",
    "    # press privacy policy button by LINK_TEXT from html/web inspection page\n",
    "    \n",
    "    try:\n",
    "        button = driver.find_element(By.LINK_TEXT, \"privacy policy\")\n",
    "        button.click()\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "        current = \"N/A\"\n",
    "        print(current)\n",
    "        return current\n",
    "    \n",
    "    \n",
    "    # close unused tabs, url for privacy policy is child window\n",
    "#     p = driver.window_handles[0]\n",
    "#     c = driver.window_handles[1]\n",
    "#     driver.switch_to.window(c)\n",
    "    \n",
    "#     WebDriverWait(driver, 2)\n",
    "    \n",
    "#     current = driver.current_url\n",
    "#     print(current)\n",
    "    comp = driver.current_url\n",
    "    tabs_open = len(driver.window_handles)\n",
    "\n",
    "    if tabs_open > 1:        \n",
    "        p = driver.window_handles[0]\n",
    "        c = driver.window_handles[1]\n",
    "        driver.switch_to.window(c)\n",
    "\n",
    "        WebDriverWait(driver, 4)\n",
    "\n",
    "        current = driver.current_url\n",
    "        print(current)\n",
    "        # close child window and switch to original/parent window\n",
    "        driver.close()\n",
    "    \n",
    "        driver.switch_to.window(p)\n",
    "    else:\n",
    "        WebDriverWait(driver, 2)\n",
    "        current = driver.current_url\n",
    "        print(current)\n",
    "\n",
    "    sleep(1)\n",
    "\n",
    "    # return privacy policy url for df\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e978c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scroll search page to get all returned app url's and id's\n",
    "def scroll(driver, timeout):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    scroll_pause_time = timeout\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause_time)\n",
    "        \n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "            \n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d44e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get urls from search\n",
    "# def get_urls(starts_with):\n",
    "#     http = httplib2.Http()\n",
    "#     chrome_options = webdriver.ChromeOptions()\n",
    "#     chrome_options.add_argument(\"--incognito\")\n",
    "#     if platform.system() == 'Windows':\n",
    "#         driver = webdriver.Chrome(executable_path='./chromedriver.exe')\n",
    "#     else:\n",
    "#         if platform.system() == 'Darwin':\n",
    "#             driver = webdriver.Chrome()\n",
    "#     # wait for page to load\n",
    "#     driver.implicitly_wait(30)\n",
    "#     # provide url(s) for driver\n",
    "#     driver.get(\"https://play.google.com/store/search?q=\" + starts_with  + \"&c=apps\")\n",
    "#     # scroll to get all apps\n",
    "#     scroll(driver, 2)\n",
    "\n",
    "#     # read and obtain all urls\n",
    "#     if platform.system() == 'Windows':\n",
    "#         soup_a = BeautifulSoup(driver.page_source, features='html.parser')\n",
    "#     else:\n",
    "#         if platform.system() == 'Darwin':\n",
    "#             soup_a = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "#     driver.close()\n",
    "\n",
    "#     # copy all urls\n",
    "#     urls = []\n",
    "#     for link in soup_a.find_all('a'):\n",
    "#         urls.append(link.get('href'))\n",
    "#     return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd6ac2bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "# categories = [\"Daydream\", \"Beauty\", \"Auto & Vehicles\", \"Business\", \"Comics\", \"Books & Reference\", \"Dating\", \"Education\", \"Communication\", \"Food & Drink\", \"Entertainment\", \"Health & Fitness\", \"Events\", \"Finance\", \"Libraries & Demo\", \"House & Home\", \"Lifestyle\", \"Medical\", \"Maps & Navigation\", \"News & Magazines\", \"Audio\", \"Personalization\", \"Photography\", \"Parenting\", \"Shopping\", \"Productivity\", \"Tools\", \"Social\", \"Sports\", \"Video Players & Editors\", \"Travel & Local\", \"Weather\",\n",
    "#               \"Adventure\", \"Arcade\", \"Action\", \"Board\", \"Casino\", \"Casual\", \"Card\", \"Music\", \"Puzzle\", \"Educational\", \"Role Playing\", \"Racing\", \"Sports\", \"Strategy\", \"Simulation\", \"Brain Games\", \"Trivia\", \"Word\", \"Education\", \"Creativity\", \"Video\", \"TV\", \"Weather\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
    "# categories = ['word']\n",
    "# urls = []\n",
    "# alphabet = 'ab'\n",
    "\n",
    "# loop through search categories and add to urls array\n",
    "# for char_index in range(len(categories)):\n",
    "#     print(categories[char_index])\n",
    "#     urls += get_urls(categories[char_index])\n",
    "#     print(urls[char_index])\n",
    "# print(len(urls))\n",
    "# for i in range(len(urls)):\n",
    "#     print(urls[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd7b6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_safety_urls(app_ids):\n",
    "    \n",
    "    base_url = \"https://play.google.com/store/apps/datasafety?id=\"\n",
    "    data_urls = []\n",
    "    \n",
    "    data_urls = [base_url + s for s in app_ids]\n",
    "    \n",
    "    return data_urls\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "555825cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_app_data_dataframe(unique_apps):\n",
    "    unique_app_ids = []\n",
    "    invalid_app_ids=[]\n",
    "    app_names = []\n",
    "    app_categories=[]\n",
    "    app_downloads=[]\n",
    "    app_score=[]\n",
    "    app_ratings=[]\n",
    "    app_developer_name=[]\n",
    "    app_developer_address=[]\n",
    "    app_version_number=[]\n",
    "    app_privacy_policy_url=[]\n",
    "    app_privacy_policy_date=[]\n",
    " \n",
    "\n",
    "    for app_id in unique_apps:\n",
    "        try:\n",
    "            app_data = app(app_id)\n",
    "        except:\n",
    "            invalid_app_ids.append(app_id)\n",
    "        else:\n",
    "            unique_app_ids.append(app_data['appId'])    \n",
    "            app_names.append(app_data['title'])\n",
    "            app_categories.append(app_data['genre'])\n",
    "            app_downloads.append(app_data['realInstalls'])\n",
    "            app_score.append(app_data['score'])\n",
    "            app_ratings.append(app_data['ratings'])\n",
    "            app_developer_name.append(app_data['developer'])\n",
    "            app_developer_address.append(app_data['developerAddress'])\n",
    "            app_version_number.append(app_data['version'])\n",
    "            app_privacy_policy_url.append(app_data['privacyPolicy'])\n",
    "            app_privacy_policy_date.append(app_data['released'])\n",
    "\n",
    "    if(exists('./invalid_app_ids_list.xlsx')):\n",
    "        invalid_app_data=pd.read_excel('./invalid_app_ids_list.xlsx')\n",
    "        invalid_app_df = pd.DataFrame({\"Invalid App IDs\": invalid_app_data['Invalid App IDs'].to_list()+invalid_app_ids})\n",
    "        invalid_app_df.to_excel (r'./invalid_app_ids_list.xlsx', index = False, header=True)\n",
    "    else:\n",
    "        invalid_app_df = pd.DataFrame({\"Invalid App IDs\": invalid_app_ids})\n",
    "        invalid_app_df.to_excel (r'./invalid_app_ids_list.xlsx', index = False, header=True)         \n",
    "\n",
    "    if(exists('./crawled_app_metadata.xlsx')):\n",
    "        app_metadata = pd.read_excel('./crawled_app_metadata.xlsx')            \n",
    "        app_metadata_obj={\n",
    "            \"Application Name\": app_metadata['Application Name'].to_list()+app_names,\n",
    "            \"Application ID\": app_metadata['Application ID'].to_list()+unique_app_ids,\n",
    "            \"Category\": app_metadata['Category'].to_list()+app_categories,\n",
    "            \"Downloads\": app_metadata['Downloads'].to_list()+app_downloads,\n",
    "            \"Score\": app_metadata['Score'].to_list()+app_score,\n",
    "            \"Ratings\": app_metadata['Ratings'].to_list()+app_ratings,\n",
    "            \"Developer Name\": app_metadata['Developer Name'].to_list()+app_developer_name,\n",
    "            \"Developer Address\": app_metadata['Developer Address'].to_list()+app_developer_address,\n",
    "            \"Version\": app_metadata['Version'].to_list()+app_version_number,\n",
    "            \"Privacy Policy URL\": app_metadata['Privacy Policy URL'].to_list()+app_privacy_policy_url,\n",
    "            \"Privacy Policy Date\": app_metadata['Privacy Policy Date'].to_list()+app_privacy_policy_date\n",
    "        }\n",
    "        app_metadata_df = pd.DataFrame(app_metadata_obj)\n",
    "        app_metadata_df.to_excel (r'./crawled_app_metadata.xlsx', index = False, header=True)\n",
    "    else:\n",
    "        app_metadata_obj={\n",
    "            \"Application Name\": app_names,\n",
    "            \"Application ID\": unique_app_ids,\n",
    "            \"Category\": app_categories,\n",
    "            \"Downloads\": app_downloads,\n",
    "            \"Score\": app_score,\n",
    "            \"Ratings\": app_ratings,\n",
    "            \"Developer Name\": app_developer_name,\n",
    "            \"Developer Address\": app_developer_address,\n",
    "            \"Version\": app_version_number,\n",
    "            \"Privacy Policy URL\": app_privacy_policy_url,\n",
    "            \"Privacy Policy Date\": app_privacy_policy_date\n",
    "        }\n",
    "        app_metadata_df = pd.DataFrame(app_metadata_obj)\n",
    "        app_metadata_df.to_excel (r'./crawled_app_metadata.xlsx', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0d4edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_app_ids_from_search(app_ids, start_index, end_index, data):\n",
    "    print('Starting Play Store Crawl for similar apps......')\n",
    "    similar_or_other_app_ids = []\n",
    "    app_ids_searched=[]\n",
    "    unique_app_list = pd.read_excel('./unique_app_ids_list.xlsx')\n",
    "    for index,app_id in enumerate(app_ids[start_index:end_index+1]):\n",
    "        url = data['play_store_search_url']+app_id+'&c=apps' \n",
    "        http = httplib2.Http()\n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        chrome_options.add_argument(\"--incognito\")\n",
    "        if platform.system() == 'Windows':\n",
    "            driver = webdriver.Chrome(executable_path='./chromedriver.exe')\n",
    "        else:\n",
    "            if platform.system() == 'Darwin':\n",
    "                driver = webdriver.Chrome()\n",
    "        \n",
    "        driver.implicitly_wait(30)\n",
    "        # provide url(s) for driver\n",
    "        driver.get(url)\n",
    "        # scroll to get all apps\n",
    "        scroll(driver, 2)\n",
    "\n",
    "        # read and obtain all urls\n",
    "        if platform.system() == 'Windows':\n",
    "            soup_a = BeautifulSoup(driver.page_source, features='html.parser')\n",
    "        else:\n",
    "            if platform.system() == 'Darwin':\n",
    "                soup_a = BeautifulSoup(driver.page_source, 'lxml')    \n",
    "        driver.close()\n",
    "        # copy all urls\n",
    "        similar_app_urls = []\n",
    "        for link in soup_a.find_all('a'):\n",
    "            similar_app_urls.append(link.get('href'))\n",
    "        similar_app_ids = [val[23:] for val in similar_app_urls if val.startswith('/store/apps/details?id=')]\n",
    "        similar_or_other_app_ids = similar_or_other_app_ids + similar_app_ids \n",
    "        app_ids_searched = app_ids_searched + [app_id]*len(similar_app_ids)\n",
    "        unique_app_list.at[start_index+index,'Searched Similar Apps'] = True \n",
    "\n",
    "\n",
    "    # Start similar app search \n",
    "    if(exists('./similar_app_mappings_data.xlsx')):\n",
    "        app_mappings = pd.read_excel('./similar_app_mappings_data.xlsx')            \n",
    "        mappings_obj = {\n",
    "            \"App ID\": app_mappings['App ID'].to_list()+app_ids_searched,\n",
    "            \"Similar App ID\": app_mappings['Similar App ID'].to_list()+similar_or_other_app_ids\n",
    "        }\n",
    "        app_mappings_df = pd.DataFrame(mappings_obj)\n",
    "        app_mappings_df.to_excel (r'./similar_app_mappings_data.xlsx', index = False, header=True)\n",
    "    else:\n",
    "        mappings_obj = {\n",
    "            \"App ID\": app_ids_searched,\n",
    "            \"Similar App ID\": similar_or_other_app_ids\n",
    "        }\n",
    "        app_mappings_df = pd.DataFrame(mappings_obj)\n",
    "        app_mappings_df.to_excel (r'./similar_app_mappings_data.xlsx', index = False, header=True)\n",
    "    # Get unique URLs among similar_or_other_app_urls\n",
    "    unique_similar_app_ids=[]\n",
    "    seen_again = set()\n",
    "    for item in similar_or_other_app_ids:\n",
    "        if item not in seen_again:\n",
    "            seen_again.add(item)\n",
    "            unique_similar_app_ids.append(item) \n",
    "    #  Compare URLs in app_urls with unique_similar_app_urls to see which URLs are new and add them to sheet\n",
    "    new_similar_apps = [id for id in unique_similar_app_ids if id not in app_ids]\n",
    "    new_similar_apps_obj = {\n",
    "        \"App ID\": unique_app_list['App ID'].to_list() + new_similar_apps,\n",
    "        \"Searched Similar Apps\": unique_app_list['Searched Similar Apps'].to_list() + [False]*len(new_similar_apps)\n",
    "    }\n",
    "    updated_apps_df = pd.DataFrame(new_similar_apps_obj)\n",
    "    updated_apps_df.to_excel(r'./unique_app_ids_list.xlsx', index = False, header=True)\n",
    "    create_app_data_dataframe(new_similar_apps) \n",
    "    print(\"Total number of apps found after similar app search: \", len(app_ids+new_similar_apps))    \n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bea4f68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Play Store Crawl for similar apps......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raghunandhan\\miniconda3\\envs\\canicopyyours\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  if sys.path[0] == \"\":\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of apps found after similar app search:  13063\n"
     ]
    }
   ],
   "source": [
    "with open(\"config.json\") as json_data_file:\n",
    "    data = json.load(json_data_file)\n",
    "\n",
    "def get_collection_or_category_urls(collection_or_category_name, collection_or_category, geographic_location):\n",
    "    url = 'https://play.google.com/store/apps/' + collection_or_category +'/' + collection_or_category_name + '?gl=' + geographic_location\n",
    "    http = httplib2.Http()\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "    if platform.system() == 'Windows':\n",
    "        driver = webdriver.Chrome(executable_path='./chromedriver.exe')\n",
    "    else:\n",
    "        if platform.system() == 'Darwin':\n",
    "            driver = webdriver.Chrome()\n",
    "    driver.implicitly_wait(30)\n",
    "    # provide url(s) for driver\n",
    "    driver.get(url)\n",
    "    # scroll to get all apps\n",
    "    scroll(driver, 2)\n",
    "\n",
    "    # read and obtain all urls\n",
    "    if platform.system() == 'Windows':\n",
    "        soup_a = BeautifulSoup(driver.page_source, features='html.parser')\n",
    "    else:\n",
    "        if platform.system() == 'Darwin':\n",
    "            soup_a = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "    driver.close()\n",
    "\n",
    "    # copy all urls\n",
    "    urls = []\n",
    "    for link in soup_a.find_all('a'):\n",
    "        urls.append(link.get('href'))\n",
    "    app_ids = [val[23:] for val in urls if val.startswith('/store/apps/details?id=')]\n",
    "    # print(\"No. of apps found for \" + collection_or_category + \" \" + collection_or_category_name + \":\", len(app_urls))    \n",
    "    # print(app_urls)\n",
    "    return app_ids\n",
    "\n",
    "if(exists('./unique_app_ids_list.xlsx')):\n",
    "    unique_app_list = pd.read_excel('./unique_app_ids_list.xlsx')\n",
    "    already_searched = [status for status in unique_app_list['Searched Similar Apps'].to_list() if status == True]\n",
    "    if len(unique_app_list['App ID']) == len(already_searched):\n",
    "        print('Start Crawling from scratch again.')\n",
    "    else:\n",
    "        # Search for Similar apps for 160 apps every time\n",
    "        get_similar_app_ids_from_search(unique_app_list['App ID'].to_list(),len(already_searched),len(already_searched)+8, data)        \n",
    "else:\n",
    "    print('Starting initial Play Store Crawl for apps......')\n",
    "    all_urls = []\n",
    "    geo_locations = []\n",
    "    for location in data['gl']:\n",
    "        geo_locations.append(data['gl'][location])\n",
    "    for gl_code in geo_locations:\n",
    "        for config_key in data['category']:\n",
    "            all_urls = all_urls + get_collection_or_category_urls(data['category'][config_key],'category',gl_code)\n",
    "        for config_key in data['collection']:\n",
    "            all_urls = all_urls + get_collection_or_category_urls(data['collection'][config_key],'collection',gl_code) \n",
    "    seen = set()\n",
    "    initial_unique_ids = []\n",
    "    for item in all_urls:\n",
    "        if item not in seen:\n",
    "            seen.add(item)\n",
    "            initial_unique_ids.append(item)\n",
    "    initial_app_obj={\n",
    "        \"App ID\": initial_unique_ids,\n",
    "        \"Searched Similar Apps\": [False]*len(initial_unique_ids)\n",
    "    }\n",
    "    initial_app_df = pd.DataFrame(initial_app_obj)\n",
    "    initial_app_df.to_excel(r'./unique_app_ids_list.xlsx', index = False, header=True)\n",
    "    create_app_data_dataframe(initial_unique_ids)     \n",
    "    print(\"Total number of apps found initially: \", len(initial_unique_ids))\n",
    "    get_similar_app_ids_from_search(initial_app_df['App ID'].to_list(),0,3,data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76a711c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extra characters from urls array to get only app ids\n",
    "# for i in range(len(total_unique_urls)):\n",
    "#     total_unique_urls[i] = total_unique_urls[i][23:]\n",
    "#     print(total_unique_urls[i])\n",
    "# print(len(total_unique_urls))\n",
    "# print(\"------------------------------------------------------------------------------------------------------------\")\n",
    "# data_urls = get_data_safety_urls(total_unique_urls)\n",
    "# print(len(data_urls))\n",
    "# print(data_urls, total_unique_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97a292cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('max_colwidth', 400)\n",
    "# df = pd.DataFrame(data_urls, columns=['data safety urls'])\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b38a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appid_df = pd.DataFrame(app_ids, columns=['app id'])\n",
    "# display(appid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9e690de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_app_ids_from_page(driver):\n",
    "    scroll(driver, 2)\n",
    "\n",
    "    # read and obtain all urls\n",
    "    if platform.system() == 'Windows':\n",
    "        soup_a = BeautifulSoup(driver.page_source, features='html.parser')\n",
    "    else:\n",
    "        if platform.system() == 'Darwin':\n",
    "            soup_a = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    # copy all urls\n",
    "    urls = []\n",
    "    for link in soup_a.find_all('a'):\n",
    "        urls.append(link.get('href'))\n",
    "    return [val for val in urls if val.startswith('/store/apps/details?id=')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5455a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "           \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f801110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar_or_other_app_ids = []\n",
    "# similar_app_id_mappings = []\n",
    "# # app_url_list = ['/store/apps/details?id=com.whatsapp','/store/apps/details?id=com.ludo.king']\n",
    "\n",
    "# for app_url in total_unique_urls:\n",
    "#     url = data['play_store_base_url']+app_url \n",
    "#     https://play.google.com/store/search?q=com.prankcall.fakecalling.huggywuggy&c=apps\n",
    "#     http = httplib2.Http()\n",
    "#     chrome_options = webdriver.ChromeOptions()\n",
    "#     chrome_options.add_argument(\"--incognito\")\n",
    "#     if platform.system() == 'Windows':\n",
    "#         driver = webdriver.Chrome(executable_path='./chromedriver.exe')\n",
    "#     else:\n",
    "#         if platform.system() == 'Darwin':\n",
    "#             driver = webdriver.Chrome()\n",
    "    \n",
    "#     driver.get(url)\n",
    "#     similar_app_links = driver.find_elements(\"xpath\",\"//a[contains(@aria-label, 'See more information on Similar') and contains(@href, '/store/apps/collection/cluster')]\")\n",
    "#     # same_developer_app_links = driver.find_elements(\"xpath\",\"//a[contains(@aria-label, 'See more information on') and contains(@href, '/store/apps/dev')]\")\n",
    "#     if len(similar_app_links)>0:\n",
    "#         similar_app_links[0].click()\n",
    "#         similar_app_ids = get_app_ids_from_page(driver)\n",
    "#         similar_app_id_mappings.append(similar_app_ids)\n",
    "#         similar_or_other_app_ids = similar_or_other_app_ids + similar_app_ids\n",
    "#     else:\n",
    "#         similar_app_id_mappings.append([])    \n",
    "\n",
    "#     # urls = []\n",
    "#     # for link in soup_a.find_all('a'):\n",
    "#     #     urls.append(link.get('href'))\n",
    "#     # app_urls = [val for val in urls if val.startswith('/store/apps/details?id=')]\n",
    "# combined_app_urls = total_unique_urls + similar_or_other_app_ids\n",
    "# seen_again = set()\n",
    "# final_unique_urls = []\n",
    "# for item in combined_app_urls:\n",
    "#     if item not in seen_again:\n",
    "#         seen.add(item)\n",
    "#         final_unique_urls.append(item)     \n",
    "# print(\"Total number of apps found: \", len(final_unique_urls))\n",
    "# print(final_unique_urls)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b56852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28150fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b78d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from htmldate import find_date\n",
    "# date = find_date('http://gammaplay.com/privacy_policy.php')\n",
    "# print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0784d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate app id and data safety urls dfs\n",
    "# df = pd.DataFrame(data_urls, columns=['data safety urls'])\n",
    "# appid_df = pd.DataFrame(total_unique_urls, columns=['app id'])\n",
    "# pd.set_option('max_colwidth', 400)\n",
    "# all_df = pd.concat([appid_df, df], axis=1, ignore_index=True)\n",
    "\n",
    "# all_df.columns = ['app id', 'data safety url']\n",
    "# display(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6183a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# darr = all_df['data safety url'].to_numpy()\n",
    "# print(darr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a11e8da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# press privacy policy button on page\n",
    "# if platform.system() == 'Windows':\n",
    "#         driver = webdriver.Chrome(executable_path='./chromedriver.exe')\n",
    "# else:\n",
    "#     if platform.system() == 'Darwin':\n",
    "#         driver = webdriver.Chrome()\n",
    "# driver.implicitly_wait(2)\n",
    "# temp = []\n",
    "# df = pd.DataFrame(columns=['privacy_policy_url'])\n",
    "# for i in darr:\n",
    "# #     temp += press_button(driver, i)\n",
    "#     df = df.append({'privacy_policy_url':press_button(driver,i)}, ignore_index=True)\n",
    "# #     urls = urls.append({'privacy_policy_url': str(priv_url)}, ignore_index=True)\n",
    "# #     print(i)\n",
    "# # urls = url.concat(urls, df)\n",
    "# # df.insert(loc=0, column = 'privacy_policy_url', value=temp)\n",
    "# driver.close()\n",
    "# # display(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f3f1aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a75026d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d52a807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df.index))\n",
    "# print(len(all_df.index))\n",
    "\n",
    "\n",
    "# merged = pd.concat([df, all_df], axis=1)\n",
    "# display(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "107e9966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome()\n",
    "# driver.implicitly_wait(2)\n",
    "# temp = press_button(driver, \"https://play.google.com/store/apps/datasafety?id=com.apple.atve.androidtv.appletv\")\n",
    "# df.insert(loc=1, column = 'privacy policy url', value=temp)\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ca15cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link = \"https://www.apple.com/legal/privacy/pdfs/apple-privacy-policy-en-ww.pdf\"\n",
    "# policy = []\n",
    "\n",
    "# r = requests.get(link)\n",
    "# f = io.BytesIO(r.content)\n",
    "\n",
    "# reader = PdfFileReader(f)\n",
    "# count = reader.numPages\n",
    "\n",
    "# for i in range(count):\n",
    "#     policy += reader.getPage(i).extractText().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72c5ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc7b83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin working sample of reading privacy policy html page with no dropdown menu's\n",
    "\n",
    "# url = \"https://snap.com/en-US/privacy/privacy-policy\"\n",
    "# url = \"https://www.whatsapp.com/legal/privacy-policy\"\n",
    "\n",
    "# res = requests.get(url)\n",
    "# html_page = res.content\n",
    "\n",
    "# soup = BeautifulSoup(html_page, 'html.parser')\n",
    "# text = soup.find_all(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "487400c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set([t.parent.name for t in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "318e3638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = ''\n",
    "# blacklist = [\n",
    "#     '[document]',\n",
    "#    'noscript',\n",
    "#     'header',\n",
    "#     'html',\n",
    "#     'meta',\n",
    "#     'head', \n",
    "#     'input',\n",
    "#     'script',\n",
    "#     'link',\n",
    "#     'style'\n",
    "# ]\n",
    "\n",
    "# for t in text:\n",
    "#     if t.parent.name not in blacklist:\n",
    "#         output += '{} '.format(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35ca820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output)\n",
    "\n",
    "# end html page read"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('canicopyyours')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "af53a71ad076c5c5da371ae436b1f1878af5d74c403f9a1269d969bda97a8e49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
